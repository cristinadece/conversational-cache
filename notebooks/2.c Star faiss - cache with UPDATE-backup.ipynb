{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f5644eb-6c34-46d3-8b78-4d07201d3f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bb342c7-82ed-4d0f-88fb-33b531aa4b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/data3/muntean/DRhard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c03b1191-fbfb-4aad-9799-b2290a192a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data3/muntean/DRhard/DRhard/lib/python3.8/site-packages/torch-1.7.0-py3.8-linux-x86_64.egg/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 803: system has unsupported display driver / cuda driver combination (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import subprocess\n",
    "import sys\n",
    "sys.path.append(\"./\")\n",
    "import faiss\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "# import torch\n",
    "from transformers import RobertaConfig\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "\n",
    "from model import RobertaDot\n",
    "from dataset import (\n",
    "    TextTokenIdsCache, load_rel, SubsetSeqDataset, SequenceDataset,\n",
    "    single_get_collate_function\n",
    ")\n",
    "from retrieve_utils import (\n",
    "    construct_flatindex_from_embeddings, \n",
    "    index_retrieve, convert_index_to_gpu,\n",
    "    update_flatindex_from_embeddings\n",
    ")\n",
    "logger = logging.Logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95697847-503b-4c85-9a68-58df9fe970b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_memmap_path = \"/data3/muntean/DRhard/data/passage/evaluate/star/passages.memmap\"\n",
    "docid_memmap_path = \"/data3/muntean/DRhard/data/passage/evaluate/star/passages-id.memmap\"\n",
    "query_memmap_path = \"/data3/muntean/DRhard/data/passage/evaluate/star/test-manual-query.memmap\"\n",
    "queryids_memmap_path = \"/data3/muntean/DRhard/data/passage/evaluate/star/test-manual-query-id.memmap\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "064b43b7-40d8-471a-b21f-e030c9ce1dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embeddings = np.memmap(doc_memmap_path, dtype=np.float32, mode=\"r\")\n",
    "doc_ids = np.memmap(docid_memmap_path, dtype=np.int32, mode=\"r\")\n",
    "doc_embeddings = doc_embeddings.reshape(-1, 768)\n",
    "\n",
    "query_embeddings = np.memmap(query_memmap_path, dtype=np.float32, mode=\"r\")\n",
    "query_embeddings = query_embeddings.reshape(-1, 768)\n",
    "query_ids = np.memmap(queryids_memmap_path, dtype=np.int32, mode=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4380dbc8-548d-479b-b1e8-c984dbc62cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 2 µs, total: 4 µs\n",
      "Wall time: 8.34 µs\n",
      "embedding shape: (38626614, 768)\n",
      "(38626614,) int64\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "index = construct_flatindex_from_embeddings(doc_embeddings, doc_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8c2d248-ab49-48e0-b5de-367bdf0f245b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "faiss.swigfaiss.IndexIDMap2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40335fb8-c5b0-4be5-8894-2b81f3a6fa74",
   "metadata": {},
   "source": [
    "# Select certain queries and certain docs for small index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9fce66a-3f25-42e3-8eb1-94b477fd712c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479\n",
      "38626614\n"
     ]
    }
   ],
   "source": [
    "# Load our qid and docid remapping dictionaries\n",
    "\n",
    "# query id dict\n",
    "qid_mapping_path = \"/data3/muntean/DRhard/data/passage/dataset/queries.CASTmanual.QID2newID.test.tsv\"\n",
    "queries_df = pd.read_csv(qid_mapping_path, delimiter=\"\\t\", header=None)\n",
    "print(len(queries_df))\n",
    "\n",
    "# collection id dict\n",
    "collection_mapping_path = \"/data3/muntean/DRhard/data/passage/dataset/CASTcollectionPID2newID.tsv\"\n",
    "collection_df = pd.read_csv(collection_mapping_path, delimiter=\"\\t\", header=None)\n",
    "print(len(collection_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc674760-7d63-4bd6-92fd-5bce892259af",
   "metadata": {},
   "outputs": [],
   "source": [
    "qid2newqid_dict = dict(zip(queries_df[0], queries_df[1])) \n",
    "pid2newpid_dict = dict(zip(collection_df[0], collection_df[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb9bbdf2-5905-4820-9141-d9eb2939adcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qid2newqid_dict[\"32_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80f062ce-28ee-4415-83e7-f3019be07308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reverse dictionaries\n",
    "newqid2qid_dict = dict(zip(queries_df[1], queries_df[0])) \n",
    "newpid2pid_dict = dict(zip(collection_df[1], collection_df[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c3ce1de-233a-4bcf-8444-260e671fd08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'32_1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newqid2qid_dict[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcf29fa9-d116-4371-95a7-c407e175dec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DRhard docid and qid encoding\n",
    "preprocess_dir = \"/data3/muntean/DRhard/data/passage/preprocess\"\n",
    "\n",
    "pid2offset = pickle.load(open(os.path.join(preprocess_dir, \"pid2offset.pickle\"), 'rb'))\n",
    "offset2pid = {v:k for k, v in pid2offset.items()}\n",
    "qid2offset = pickle.load(open(os.path.join(preprocess_dir, f\"test-manual-qid2offset.pickle\"), 'rb'))\n",
    "offset2qid = {v:k for k, v in qid2offset.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fda4ab8-b818-4efc-880d-56f3678523bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qid2offset[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40d74880-f7f5-440b-aee0-0db70fa1d168",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_qrel_int = [31, 32, 33, 34, 37, 40, 49, 50, 54, 56, 58, 59, 61, 67, 68, 69, 75, 77, 78, 79]\n",
    "conv_qrel = [str(x) for x in conv_qrel_int]\n",
    "# conv_qrel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a6855b-09d7-4f63-bdc2-ddd7900333ba",
   "metadata": {},
   "source": [
    "# Create conv cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cf060aa8-3cc8-49da-9673-aaad5a0cc79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = 5000 # cache dimension [1000,2000,5000,10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c8b6a11a-a764-474e-9665-a167849a95f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance dicts\n",
    "cache_radius_dict = dict() # between first utterance (qa) and last retrieved doc from the big index\n",
    "query_distance_dict = dict() # distance between the first (qa) and the rest of utterances of the conversation (qb)\n",
    "query_radius_dict = dict() # between current utterance (qb) and last retrieved doc from the big index\n",
    "rb_hat_dict = dict() # rb_hat = ra - d(qb, qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "93f7a3b2-c61d-4922-beb2-9c09e3322549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_distance(v1,v2):\n",
    "    return np.linalg.norm(v1-v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a477a6db-0389-451a-87b6-354a75387308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conv_cache(conv_id, qid2newqid_dict, qid2offset, query_embeddings, doc_embeddings, \n",
    "                      index, topk, cache_radius_dict):\n",
    "    # first utt of the conversation - determines the size of the cache\n",
    "    first_qid = conv_id + \"_1\"\n",
    "    newqid = qid2newqid_dict[first_qid] #added first\n",
    "    qid_offset = qid2offset[newqid]\n",
    "\n",
    "    # prendere il memmap\n",
    "    query_emb = query_embeddings[qid_offset].reshape(1, 768)\n",
    "    print(\"Init index: \",first_qid, qid_offset)\n",
    "    \n",
    "    # fare retireval nel indice grande e prendere top 2000 documenti\n",
    "    faiss.omp_set_num_threads(16) #32\n",
    "    nearest_neighbors = index_retrieve(index, query_emb, topk, batch=32)\n",
    "    \n",
    "    # select doc embeddings, paired with ids\n",
    "    small_doc_emb = doc_embeddings[nearest_neighbors[0]]\n",
    "    small_doc_ids = np.array(nearest_neighbors[0])\n",
    "    index_conv = construct_flatindex_from_embeddings(small_doc_emb, small_doc_ids)\n",
    "       \n",
    "    # compute distance between the first query and last doc in the list of topk retrieved that are stored in cache (e.g., r_q_i)\n",
    "    last_doc = nearest_neighbors[0][-1]\n",
    "    last_doc_embedding = doc_embeddings[last_doc]\n",
    "    cache_radius_dict[first_qid] = l2_distance(query_emb, last_doc_embedding)\n",
    "    \n",
    "    return index_conv, nearest_neighbors, cache_radius_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7a8044c5-9377-4c08-84f0-adc28f911873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_conv_cache(qid, qid2newqid_dict, qid2offset, query_embeddings, doc_embeddings, \n",
    "                      index, index_conv, topk, cache_radius_dict):\n",
    "    # determines the size of the cache?\n",
    "    newqid = qid2newqid_dict[qid]\n",
    "    qid_offset = qid2offset[newqid]\n",
    "\n",
    "    # prendere il memmap\n",
    "    query_emb = query_embeddings[qid_offset].reshape(1, 768)\n",
    "    \n",
    "    print(\"Update index: \",qid, qid_offset)\n",
    "    \n",
    "    # fare retireval nel indice grande e prendere topk documenti\n",
    "    faiss.omp_set_num_threads(16) #32\n",
    "    nearest_neighbors = index_retrieve(index, query_emb, topk, batch=32)\n",
    "    \n",
    "    # select doc embeddings, paired with ids\n",
    "    small_doc_emb = doc_embeddings[nearest_neighbors[0]]\n",
    "    small_doc_ids = np.array(nearest_neighbors[0])\n",
    "    index_conv = update_flatindex_from_embeddings(index_conv, small_doc_emb, small_doc_ids)\n",
    "       \n",
    "    # compute distance between the first query and last doc in the list of topk retrieved that are stored in cache (e.g., r_q_i)\n",
    "    last_doc = nearest_neighbors[0][-1]\n",
    "    last_doc_embedding = doc_embeddings[last_doc]\n",
    "    cache_radius_dict[qid] = l2_distance(query_emb, last_doc_embedding)\n",
    "    \n",
    "    return index_conv, nearest_neighbors, cache_radius_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d60652-5641-4b15-bda6-eec00863730c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting conv:  32\n",
      "Init index:  32_1 9\n",
      "Query Num 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                                                                                                | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:59<00:00, 59.46s/it]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 59.5s, Elapsed Time per query: 59467.2ms\n",
      "embedding shape: (5000, 768)\n",
      "(5000,) int64\n",
      "Create cache for:  32\n",
      "\n",
      "Processing qid: 32_2 10\n",
      "One query in cache, rb_hat di 32_2  is  1.3569245\n",
      "Query Num 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 208.67it/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 0.0s, Elapsed Time per query: 8.6ms\n",
      "Retrieved top 1000 for 32_2\n",
      "Query Num 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                                                                                                | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:28<00:00, 28.96s/it]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 29.0s, Elapsed Time per query: 28963.3ms\n",
      "Finished retrieving in the big index!\n",
      "Check this when update happens: [5696924, 5231421, 5231427, 34260273, 34036966, 5696927, 5696932, 34214925, 2846731, 17328200] [5696924, 5231421, 5231427, 34260273, 34036966, 5696927, 5696932, 34214925, 2846731, 17328200] [6584581, 3855636, 2174663, 3839334, 6786658, 1864967, 521815, 3839336, 706230, 2174666]\n",
      "finished with qid:  32_2\n",
      "\n",
      "Processing qid: 32_3 11\n",
      "One query in cache, rb_hat di 32_3  is  -0.09773302\n",
      "Update index:  32_3 11\n",
      "Query Num 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                                                                                                | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:58<00:00, 58.22s/it]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 58.2s, Elapsed Time per query: 58224.0ms\n",
      "embedding shape: (5000, 768)\n",
      "(5000,) int64\n",
      "Updating cache!\n",
      "Query Num 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 117.56it/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 0.0s, Elapsed Time per query: 12.1ms\n",
      "Retrieved top 1000 for 32_3\n",
      "Query Num 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                                                                                                | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:41<00:00, 41.36s/it]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 41.4s, Elapsed Time per query: 41367.3ms\n",
      "Finished retrieving in the big index!\n",
      "Check this when update happens: [2269518, 795750, 4416645, 6226326, 13143982, 7108432, 1432514, 5511406, 2174086, 673356] [2269518, 2269518, 795750, 795750, 4416645, 4416645, 6226326, 6226326, 13143982, 13143982] [2269518, 795750, 4416645, 6226326, 13143982, 7108432, 1432514, 5511406, 2174086, 673356]\n",
      "finished with qid:  32_3\n",
      "\n",
      "Processing qid: 32_4 12\n",
      "More queries in cache, rb_hat di 32_4  and  32_1  is  0.36956453\n",
      "Query Num 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 117.94it/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 0.0s, Elapsed Time per query: 11.9ms\n",
      "Retrieved top 1000 for 32_4\n",
      "Query Num 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                                                                                                | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:45<00:00, 45.94s/it]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 45.9s, Elapsed Time per query: 45941.1ms\n",
      "Finished retrieving in the big index!\n",
      "Check this when update happens: [3442961, 3594051, 5791550, 3506104, 5791552, 3559434, 7755146, 24040080, 3594048, 13257] [3442961, 3442961, 3594051, 3594051, 5791550, 5791550, 3506104, 3506104, 5791552, 5791552] [2269518, 795750, 4416645, 6226326, 13143982, 7108432, 1432514, 5511406, 2174086, 673356]\n",
      "finished with qid:  32_4\n",
      "\n",
      "Processing qid: 32_5 13\n",
      "More queries in cache, rb_hat di 32_5  and  32_1  is  0.025249958\n",
      "Query Num 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 53.08it/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 0.0s, Elapsed Time per query: 22.7ms\n",
      "Retrieved top 1000 for 32_5\n",
      "Query Num 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                                                                                                | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "# conv_ids = set([x.split(\"_\")[0] for x in qid2newqid_dict.keys()]) # this has all but we don't need all, just the ones in qrel\n",
    "# conv in qrel: subset of all conv\n",
    "conv_qrel_int = [32] #, 32, 33, 34, 37, 40, 49, 50, 54, 56, 58, 59, 61, 67, 68, 69, 75, 77, 78, 79]\n",
    "conv_qrel = [str(x) for x in conv_qrel_int]\n",
    "\n",
    "results_list = []  # top1000 rankings for each query of the conversation from the CACHE index\n",
    "cache_update_with_qid = []\n",
    "coverage1 = {} # top10 ranking for each query from the BIG index\n",
    "coverage2 = {} # list of triples (3,5,10) for each qb\n",
    "\n",
    "for conv_id in conv_qrel: # iterate over the conversations\n",
    "    print()\n",
    "    print()\n",
    "    print(\"Starting conv: \" , conv_id)\n",
    "    \n",
    "    # ALL QA\n",
    "    # Create index for first query and retrieve nearest neighbours - top 2000\n",
    "    index_conv, nn_index, cache_radius_dict = create_conv_cache(conv_id, qid2newqid_dict, \n",
    "                                                                         qid2offset, query_embeddings, \n",
    "                                                                         doc_embeddings, index, topk, \n",
    "                                                                         cache_radius_dict)\n",
    "    print(\"Create cache for: \", conv_id)\n",
    "    \n",
    "    # save docs for qa for coverage\n",
    "    retrieved_qa = nn_index[0]\n",
    "        \n",
    "    # first  query id & embedding\n",
    "    first_qid = conv_id + \"_1\"\n",
    "    first_newqid = qid2newqid_dict[first_qid] #added first\n",
    "    first_qid_offset = qid2offset[first_newqid]\n",
    "    \n",
    "    # save results - top 1000 for first conv query qa\n",
    "    for idx, pid in enumerate(nn_index[0][:1000]):\n",
    "        results_list.append((first_qid_offset, pid, idx+1))\n",
    "    \n",
    "    # prendere il memmap di qa\n",
    "    first_query_emb = query_embeddings[first_qid_offset].reshape(1, 768)\n",
    "    \n",
    "    queries_in_cache = {}\n",
    "    queries_in_cache[first_qid] = first_query_emb\n",
    "    \n",
    "    # for each utt in the rest of the conv: qb\n",
    "    for qid in qid2newqid_dict.keys():\n",
    "        if not qid.endswith(\"_1\") and qid.startswith(conv_id):\n",
    "            \n",
    "            # select query embedding\n",
    "            newqid = qid2newqid_dict[qid]\n",
    "            qid_offset = qid2offset[newqid]\n",
    "            # prendere il memmap\n",
    "            query_emb = query_embeddings[qid_offset].reshape(1, 768)\n",
    "            \n",
    "            print()\n",
    "            print(\"Processing qid:\", qid, qid_offset)\n",
    "            \n",
    "            if len(queries_in_cache)>1: # there are more queries in cache\n",
    "                # COMPUTE rb_hat with all queries in cache based on convid\n",
    "                update = True\n",
    "                for query_in_cache_id, query_in_cache_emb  in queries_in_cache.items():\n",
    "                    query_distance_dict[qid] = l2_distance(query_emb, query_in_cache_emb)\n",
    "                    rb_hat_dict[qid] = cache_radius_dict[query_in_cache_id] - query_distance_dict[qid]\n",
    "                    print(\"More queries in cache, rb_hat di\", qid, \" and \", query_in_cache_id, \" is \", rb_hat_dict[qid])\n",
    "                    if rb_hat_dict[qid] >= 0: \n",
    "                        update = False\n",
    "                        break\n",
    "                \n",
    "                # update index and query in cache list\n",
    "                if update:\n",
    "                    print(\"Updating cache!\")\n",
    "                    queries_in_cache[qid] = query_emb\n",
    "                    index_conv, nn_index, cache_radius_dict = update_conv_cache(qid, qid2newqid_dict, qid2offset, \n",
    "                                                                                         query_embeddings, doc_embeddings, index,\n",
    "                                                                                         index_conv, topk, cache_radius_dict)\n",
    "                \n",
    "            else:\n",
    "                # COMPUTE rb_hat with first only\n",
    "                # compute distance between qb and qa\n",
    "                query_distance_dict[qid] = l2_distance(query_emb, first_query_emb)\n",
    "\n",
    "                # compute rb_capuccio = ra - d(qb, qa)\n",
    "                rb_hat_dict[qid] = cache_radius_dict[first_qid] - query_distance_dict[qid]\n",
    "                print(\"One query in cache, rb_hat di\", qid, \" is \", rb_hat_dict[qid])\n",
    "            \n",
    "                # update index and query in cache list\n",
    "                if rb_hat_dict[qid] < 0:\n",
    "                    queries_in_cache[qid] = query_emb\n",
    "                    index_conv, nn_index, cache_radius_dict = update_conv_cache(qid, qid2newqid_dict, qid2offset, \n",
    "                                                                                         query_embeddings, doc_embeddings, index,\n",
    "                                                                                         index_conv, topk, cache_radius_dict)\n",
    "                    print(\"Updating cache!\")\n",
    "                \n",
    "\n",
    "            # retrieve docs for qb\n",
    "            faiss.omp_set_num_threads(16) #32\n",
    "            nn_cache = index_retrieve(index_conv, query_emb, 1000, batch=32)\n",
    "            print(\"Retrieved top 1000 for\", qid)\n",
    "            \n",
    "            # save results - top1000, for qb\n",
    "            for idx, pid in enumerate(nn_cache[0]):\n",
    "                results_list.append((qid_offset, pid, idx+1))\n",
    "                \n",
    "            \n",
    "            #### Compute COVERAGE \n",
    "            # Cov1 - intersezione tra Ba ed Bb_hat\n",
    "            # distance between qb and each doc in top1000 from cache and check if < rb_hat\n",
    "            # put them in a list - exact match - and intersect with top k in cache\n",
    "            retrieved_qb_in_rb_hat = []\n",
    "            small_doc_emb = doc_embeddings[nn_cache[0]]\n",
    "            for doc_id, doc_emb in zip(nn_cache[0], small_doc_emb):\n",
    "                if l2_distance(query_emb, doc_emb) < rb_hat_dict[qid]:\n",
    "                    retrieved_qb_in_rb_hat.append(doc_id)\n",
    "            coverage1[qid]=retrieved_qb_in_rb_hat\n",
    "            \n",
    "            \n",
    "            #### Compute DISTANCES rb\n",
    "            \n",
    "            #compute distance between qb and the last retrieved doc from INDEX\n",
    "            first_10_docs = index_retrieve(index, query_emb, 10, batch=32)\n",
    "            # 3 raggi rb per 3,5,10\n",
    "            rb_dist_list = []\n",
    "            for i in [3,5,10]:\n",
    "                last_doc_embedding = doc_embeddings[first_10_docs[0][i-1]]\n",
    "                dist_rb = l2_distance(query_emb, last_doc_embedding)\n",
    "                rb_dist_list.append(dist_rb)\n",
    "            query_radius_dict[qid] = rb_dist_list\n",
    "            print(\"Finished retrieving in the big index!\")\n",
    "            \n",
    "            # save top10 for qb in INDEX\n",
    "            results_list_rb = first_10_docs[0][:10]\n",
    "            result_list_qb_in_cache = nn_cache[0][:10]\n",
    "            \n",
    "            print(\"Check this when update happens:\" , results_list_rb, result_list_qb_in_cache, nn_index[0][:10])\n",
    "        \n",
    "            #### Compute COVERAGE          \n",
    "            # Cov2 - intersezione tra risultati di query qb top 1000 su cache e query qb su indice per k=3,5,10\n",
    "            num_intersection = []\n",
    "            for cut_off in [3,5,10]:\n",
    "                elem_in_common = set(results_list_rb[:cut_off]).intersection(result_list_qb_in_cache[:cut_off])\n",
    "                num_intersection.append(len(elem_in_common))\n",
    "            coverage2[qid] = num_intersection    \n",
    "            \n",
    "            print(\"finished with qid: \", qid)\n",
    "    cache_update_with_qid.extend(list(queries_in_cache.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "41fa6d18-eb9c-46a8-95c6-d74f61d390f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/star-ranking/approximated-coverage-star-L2-ranking-top1000-cache-top'+str(topk)+'_with_update.tsv', 'w+') as fout:\n",
    "    for i in coverage2:\n",
    "        # print(coverage2.keys())\n",
    "        if i in cache_update_with_qid:\n",
    "            fout.write(str(i)+\"\\t\"+str(coverage2[i])+\"\\t\"+str(coverage1[i])+\"\\t\"+str(rb_hat_dict[i])+\" UPDATE \\n\")\n",
    "        else:\n",
    "            fout.write(str(i)+\"\\t\"+str(coverage2[i])+\"\\t\"+str(coverage1[i])+\"\\t\"+str(rb_hat_dict[i])+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2507c384-c52e-49d8-9a0e-9f3dff56e7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['31_1',\n",
       " '31_3',\n",
       " '32_1',\n",
       " '32_3',\n",
       " '32_6',\n",
       " '32_8',\n",
       " '33_1',\n",
       " '33_10',\n",
       " '34_1',\n",
       " '37_1',\n",
       " '37_6',\n",
       " '37_9',\n",
       " '40_1',\n",
       " '40_5',\n",
       " '40_7',\n",
       " '40_9',\n",
       " '49_1',\n",
       " '49_3',\n",
       " '50_1',\n",
       " '50_2',\n",
       " '50_5',\n",
       " '50_7',\n",
       " '54_1',\n",
       " '54_3',\n",
       " '54_8',\n",
       " '56_1',\n",
       " '56_7',\n",
       " '58_1',\n",
       " '58_7',\n",
       " '59_1',\n",
       " '59_3',\n",
       " '59_5',\n",
       " '59_7',\n",
       " '61_1',\n",
       " '61_6',\n",
       " '61_8',\n",
       " '67_1',\n",
       " '67_4',\n",
       " '67_5',\n",
       " '67_10',\n",
       " '67_11',\n",
       " '68_1',\n",
       " '68_4',\n",
       " '68_5',\n",
       " '68_7',\n",
       " '68_10',\n",
       " '69_1',\n",
       " '69_3',\n",
       " '69_5',\n",
       " '75_1',\n",
       " '75_4',\n",
       " '75_7',\n",
       " '77_1',\n",
       " '77_4',\n",
       " '77_5',\n",
       " '77_6',\n",
       " '77_8',\n",
       " '77_10',\n",
       " '78_1',\n",
       " '78_7',\n",
       " '78_10',\n",
       " '79_1',\n",
       " '79_2',\n",
       " '79_3',\n",
       " '79_4',\n",
       " '79_6',\n",
       " '79_9']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(cache_update_with_qid))\n",
    "cache_update_with_qid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c1db43b0-3ee0-48ed-8616-adb5a338b370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b95e7722-ce79-48d6-841c-9357f7da1a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ids to original\n",
    "with open(\"/data3/muntean/conversational-cache/data/star-ranking/CAST-manual-queries-star-L2-ranking-top1000-cache-top\"+str(topk)+\"-with-update.tsv\", 'w') as outputfile:\n",
    "    for (qid, pid, idx) in results_list:\n",
    "        \n",
    "        new_qid = offset2qid[qid]\n",
    "        orig_qid = newqid2qid_dict[new_qid]\n",
    "        \n",
    "        new_pid = offset2pid[pid]\n",
    "        orig_pid = newpid2pid_dict[new_pid]\n",
    "        \n",
    "        outputfile.write(f\"{orig_qid}\\t{orig_pid}\\t{idx}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f891e1-a592-4ea6-9245-966e59aa2dee",
   "metadata": {},
   "source": [
    "# Eval results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "420e75ce-8ca7-4097-8ebf-22c9c50cabb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyterrier as pt\n",
    "# pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8a43705f-a26e-4b0e-ac47-c17e764a32ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "qrel_path = \"../data/CAST_qrels/qrels-docs.2019.txt\"\n",
    "qrels_df = pd.read_csv(qrel_path, delimiter=\" \", header=None)\n",
    "qrels_df[[3]] = qrels_df[[3]].astype(int)\n",
    "qrels_df = qrels_df.drop([1], axis=1)\n",
    "qrels_df.columns=[\"qid\", \"docno\", \"label\"]\n",
    "qrels = qrels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fa18fb4e-d621-4ee3-bee5-6ae288742ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31_1</td>\n",
       "      <td>What is throat cancer?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31_2</td>\n",
       "      <td>Is throat cancer treatable?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31_3</td>\n",
       "      <td>Tell me about lung cancer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31_4</td>\n",
       "      <td>What are lung cancer's symptoms?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31_5</td>\n",
       "      <td>Can lung cancer spread to the throat?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    qid                                  query\n",
       "0  31_1                 What is throat cancer?\n",
       "1  31_2            Is throat cancer treatable?\n",
       "2  31_3             Tell me about lung cancer.\n",
       "3  31_4       What are lung cancer's symptoms?\n",
       "4  31_5  Can lung cancer spread to the throat?"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_path='../data/CAST-2019/test_manual_utterance.tsv' #manual\n",
    "\n",
    "topics_df = pd.read_csv(topics_path, delimiter=\"\\t\", header=None)\n",
    "topics_df.columns=[\"qid\", \"query\"]\n",
    "topics = topics_df\n",
    "topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3fb09f29-89af-4c8f-9def-080ba06eb30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31_1</td>\n",
       "      <td>MARCO_3878347</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31_1</td>\n",
       "      <td>MARCO_789620</td>\n",
       "      <td>2</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31_1</td>\n",
       "      <td>MARCO_291003</td>\n",
       "      <td>3</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31_1</td>\n",
       "      <td>MARCO_5625372</td>\n",
       "      <td>4</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31_1</td>\n",
       "      <td>MARCO_2954451</td>\n",
       "      <td>5</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    qid          docno  rank  score\n",
       "0  31_1  MARCO_3878347     1    999\n",
       "1  31_1   MARCO_789620     2    998\n",
       "2  31_1   MARCO_291003     3    997\n",
       "3  31_1  MARCO_5625372     4    996\n",
       "4  31_1  MARCO_2954451     5    995"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_path = \"../data/star-ranking/CAST-manual-queries-star-L2-ranking-top1000-cache-top\"+str(topk)+\"-with-update.tsv\"\n",
    "results_df = pd.read_csv(results_path, delimiter=\"\\t\", header=None)\n",
    "results_df[3] = 1000-results_df[2]\n",
    "results_df.columns=[\"qid\", \"docno\", \"rank\", \"score\"]\n",
    "results_df.head()\n",
    "# Results produced by the transformers must have “qid”, “docno”, “score”, “rank” columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f1d8219c-375a-4388-9ea7-c2b1390d03a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 421 ms, sys: 8.06 ms, total: 429 ms\n",
      "Wall time: 428 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>recip_rank</th>\n",
       "      <th>recall_200</th>\n",
       "      <th>P_3</th>\n",
       "      <th>P_1</th>\n",
       "      <th>ndcg_cut_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STAR</td>\n",
       "      <td>0.18767</td>\n",
       "      <td>0.636636</td>\n",
       "      <td>0.430454</td>\n",
       "      <td>0.489403</td>\n",
       "      <td>0.49711</td>\n",
       "      <td>0.373501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name      map  recip_rank  recall_200       P_3      P_1  ndcg_cut_3\n",
       "0  STAR  0.18767    0.636636    0.430454  0.489403  0.49711    0.373501"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pt.Experiment([results_df], topics, qrels, names=[\"STAR\"], \n",
    "              eval_metrics=[\"map\", \"recip_rank\", \"recall_200\", \"P_3\", \"P_1\", \"ndcg_cut_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "737f6f77-5186-4a8f-96df-927f989b5511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# res_per_query = pt.Experiment([results_df], topics, qrels, names=[\"STAR\"], \n",
    "#               eval_metrics=[\"map\", \"recip_rank\", \"recall_200\", \"P_3\", \"P_1\", \"ndcg_cut_3\"], perquery=True)\n",
    "# res_per_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf1a559-65fa-49ca-b9a8-4d2ff49cd42d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DRhard",
   "language": "python",
   "name": "drhard"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

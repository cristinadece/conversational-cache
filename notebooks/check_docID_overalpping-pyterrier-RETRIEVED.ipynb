{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.7.1 has loaded Terrier 5.6 (built by craigmacdonald on 2021-09-17 13:27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "pt.init()\n",
    "# pt.init(boot_packages=[\"com.github.terrierteam:terrier-prf:-SNAPSHOT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jnius import autoclass\n",
    "tokeniser = autoclass(\"org.terrier.indexing.tokenisation.Tokeniser\").getTokeniser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def terrier_tokenizer(raw_utterance):\n",
    "    new_utterance = \" \".join(tokeniser.getTokens(raw_utterance))\n",
    "    return new_utterance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve docs per query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:42:50.397 [main] WARN org.terrier.structures.BaseCompressingMetaIndex - Structure meta reading lookup file directly from disk (SLOW) - try index.meta.index-source=fileinmem in the index properties file. 294.8 MiB of memory would be required.\n",
      "14:42:50.431 [main] WARN org.terrier.structures.BaseCompressingMetaIndex - Structure meta reading data file directly from disk (SLOW) - try index.meta.data-source=fileinmem in the index properties file. 2 GiB of memory would be required.\n",
      "Number of documents: 38636520\n",
      "Number of terms: 9333281\n",
      "Number of postings: 1052145306\n",
      "Number of fields: 0\n",
      "Number of tokens: 1300558544\n",
      "Field names: []\n",
      "Positions:   false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index_ref = pt.IndexRef.of(\"/data3/muntean/conversational-cache/indexes/CAST2020-stemmed/data.properties\")\n",
    "index = pt.IndexFactory.of(index_ref)\n",
    "\n",
    "di = index.getDirectIndex()\n",
    "doi = index.getDocumentIndex()\n",
    "lex = index.getLexicon()\n",
    "\n",
    "print(index.getCollectionStatistics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrel_path = \"../data/CAST_qrels/qrels-docs.2019.txt\"\n",
    "qrels_df = pd.read_csv(qrel_path, delimiter=\" \", header=None)\n",
    "qrels_df[[3]] = qrels_df[[3]].astype(int)\n",
    "qrels_df = qrels_df.drop([1], axis=1)\n",
    "qrels_df.columns=[\"qid\", \"docno\", \"label\"]\n",
    "qrels = qrels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31_1</td>\n",
       "      <td>what is throat cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31_2</td>\n",
       "      <td>is throat cancer treatable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31_3</td>\n",
       "      <td>tell me about lung cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31_4</td>\n",
       "      <td>what are lung cancer s symptoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31_5</td>\n",
       "      <td>can lung cancer spread to the throat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    qid                                 query\n",
       "0  31_1                 what is throat cancer\n",
       "1  31_2            is throat cancer treatable\n",
       "2  31_3             tell me about lung cancer\n",
       "3  31_4       what are lung cancer s symptoms\n",
       "4  31_5  can lung cancer spread to the throat"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_path='../data/CAST-2019/test_manual_utterance.tsv' #manual\n",
    "\n",
    "topics_df = pd.read_csv(topics_path, delimiter=\"\\t\", header=None)\n",
    "\n",
    "topics_df[2] = topics_df[1].apply(lambda s: terrier_tokenizer(s))\n",
    "\n",
    "topics_df = topics_df.drop([1], axis=1)\n",
    "topics_df.columns=[\"qid\", \"query\"]\n",
    "\n",
    "topics = topics_df\n",
    "topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 54s, sys: 3.45 s, total: 1min 57s\n",
      "Wall time: 3min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "DPH_2000 = pt.BatchRetrieve(index, wmodel=\"DPH\", num_results=2000)  \n",
    "res_2000 = DPH_2000.transform(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# pt.Experiment([DPH_2000], topics, qrels, names=[\"DPH_2000\"], \n",
    "#               eval_metrics=[\"map\", \"recip_rank\", \"recall_200\", \"P_3\", \"P_1\", \"ndcg_cut_3\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_2000['rank'].astype(int)\n",
    "\n",
    "# 1. group by qid and take the first 10 docid?\n",
    "qid_list = list(topics[\"qid\"])\n",
    "qid_retrieve_docids_df = res_2000.loc[res_2000['qid'].isin(qid_list)]\n",
    "qid_retrieve_docids_df = qid_retrieve_docids_df.groupby('qid')['docno'].apply(list)\n",
    "qid_retrieve_docids_dict = qid_retrieve_docids_df.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qid_retrieve_docids_dict[\"31_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REMMBER to check the YEAR\n",
    "\n",
    "qid_rel_dict = defaultdict(int)\n",
    "path = \"../data/CAST_qrels/\"\n",
    "with open(path+\"qrels-docs.2019.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        line_fields = line.rstrip().split(\" \")\n",
    "        utt_id = line_fields[0]\n",
    "        doc_id = line_fields[2]\n",
    "        relevance = int(line_fields[3])\n",
    "        if relevance > 0:\n",
    "            qid_rel_dict[utt_id]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'31_1': 89,\n",
       "             '31_2': 77,\n",
       "             '31_3': 171,\n",
       "             '31_4': 98,\n",
       "             '31_5': 58,\n",
       "             '31_6': 63,\n",
       "             '31_7': 58,\n",
       "             '31_8': 68,\n",
       "             '31_9': 55,\n",
       "             '32_1': 96,\n",
       "             '32_2': 67,\n",
       "             '32_3': 98,\n",
       "             '32_4': 17,\n",
       "             '32_5': 43,\n",
       "             '32_6': 17,\n",
       "             '32_7': 88,\n",
       "             '32_8': 17,\n",
       "             '32_9': 20,\n",
       "             '32_10': 16,\n",
       "             '32_11': 9,\n",
       "             '33_1': 46,\n",
       "             '33_2': 17,\n",
       "             '33_3': 16,\n",
       "             '33_4': 4,\n",
       "             '33_5': 35,\n",
       "             '33_6': 24,\n",
       "             '33_7': 9,\n",
       "             '33_8': 31,\n",
       "             '34_1': 71,\n",
       "             '34_2': 32,\n",
       "             '34_3': 30,\n",
       "             '34_4': 52,\n",
       "             '34_5': 25,\n",
       "             '34_6': 30,\n",
       "             '34_7': 32,\n",
       "             '34_8': 21,\n",
       "             '37_1': 58,\n",
       "             '37_2': 22,\n",
       "             '37_3': 37,\n",
       "             '37_4': 21,\n",
       "             '37_5': 32,\n",
       "             '37_6': 74,\n",
       "             '37_7': 39,\n",
       "             '37_8': 29,\n",
       "             '40_1': 66,\n",
       "             '40_2': 18,\n",
       "             '40_3': 36,\n",
       "             '40_4': 49,\n",
       "             '40_5': 18,\n",
       "             '40_6': 81,\n",
       "             '40_7': 79,\n",
       "             '40_8': 6,\n",
       "             '49_1': 25,\n",
       "             '49_2': 18,\n",
       "             '49_3': 42,\n",
       "             '49_4': 46,\n",
       "             '49_5': 56,\n",
       "             '49_6': 60,\n",
       "             '49_7': 51,\n",
       "             '49_8': 101,\n",
       "             '50_1': 76,\n",
       "             '50_2': 111,\n",
       "             '50_3': 106,\n",
       "             '50_4': 85,\n",
       "             '50_5': 58,\n",
       "             '50_6': 19,\n",
       "             '50_7': 105,\n",
       "             '50_8': 61,\n",
       "             '54_1': 50,\n",
       "             '54_2': 28,\n",
       "             '54_3': 50,\n",
       "             '54_4': 10,\n",
       "             '54_5': 19,\n",
       "             '54_6': 8,\n",
       "             '54_7': 6,\n",
       "             '54_8': 12,\n",
       "             '54_9': 9,\n",
       "             '56_1': 106,\n",
       "             '56_2': 69,\n",
       "             '56_3': 32,\n",
       "             '56_4': 72,\n",
       "             '56_5': 55,\n",
       "             '56_6': 59,\n",
       "             '56_7': 53,\n",
       "             '56_8': 38,\n",
       "             '58_1': 29,\n",
       "             '58_2': 24,\n",
       "             '58_3': 50,\n",
       "             '58_4': 42,\n",
       "             '58_5': 52,\n",
       "             '58_6': 44,\n",
       "             '58_7': 28,\n",
       "             '58_8': 14,\n",
       "             '59_1': 35,\n",
       "             '59_2': 117,\n",
       "             '59_3': 86,\n",
       "             '59_4': 69,\n",
       "             '59_5': 24,\n",
       "             '59_6': 1,\n",
       "             '59_7': 45,\n",
       "             '59_8': 56,\n",
       "             '61_1': 145,\n",
       "             '61_2': 14,\n",
       "             '61_3': 16,\n",
       "             '61_4': 75,\n",
       "             '61_5': 53,\n",
       "             '61_6': 83,\n",
       "             '61_7': 42,\n",
       "             '61_8': 56,\n",
       "             '67_1': 43,\n",
       "             '67_2': 51,\n",
       "             '67_3': 45,\n",
       "             '67_4': 88,\n",
       "             '67_5': 135,\n",
       "             '67_6': 79,\n",
       "             '67_7': 10,\n",
       "             '67_8': 116,\n",
       "             '67_9': 88,\n",
       "             '67_10': 70,\n",
       "             '67_11': 53,\n",
       "             '68_1': 43,\n",
       "             '68_2': 17,\n",
       "             '68_3': 36,\n",
       "             '68_4': 59,\n",
       "             '68_5': 46,\n",
       "             '68_6': 35,\n",
       "             '68_7': 43,\n",
       "             '68_8': 89,\n",
       "             '68_9': 100,\n",
       "             '68_10': 70,\n",
       "             '68_11': 61,\n",
       "             '69_1': 29,\n",
       "             '69_2': 39,\n",
       "             '69_3': 13,\n",
       "             '69_4': 24,\n",
       "             '69_5': 20,\n",
       "             '69_6': 32,\n",
       "             '69_7': 5,\n",
       "             '69_8': 11,\n",
       "             '69_9': 29,\n",
       "             '69_10': 16,\n",
       "             '75_1': 17,\n",
       "             '75_2': 52,\n",
       "             '75_3': 19,\n",
       "             '75_4': 36,\n",
       "             '75_5': 25,\n",
       "             '75_6': 21,\n",
       "             '75_8': 19,\n",
       "             '77_1': 39,\n",
       "             '77_2': 5,\n",
       "             '77_3': 39,\n",
       "             '77_4': 24,\n",
       "             '77_5': 36,\n",
       "             '77_6': 40,\n",
       "             '77_7': 35,\n",
       "             '77_8': 32,\n",
       "             '78_1': 57,\n",
       "             '78_2': 16,\n",
       "             '78_3': 54,\n",
       "             '78_4': 19,\n",
       "             '78_5': 8,\n",
       "             '78_6': 4,\n",
       "             '78_7': 37,\n",
       "             '78_8': 1,\n",
       "             '79_1': 106,\n",
       "             '79_2': 107,\n",
       "             '79_3': 106,\n",
       "             '79_4': 78,\n",
       "             '79_5': 41,\n",
       "             '79_6': 77,\n",
       "             '79_7': 23,\n",
       "             '79_8': 51,\n",
       "             '79_9': 40})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qid_rel_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions to check the intersection between top-k results of current turn and top-k results of the previous turns \n",
    "\n",
    "def intersection(lst1, lst2):\n",
    "    return set(lst1).intersection(lst2)\n",
    "\n",
    "def compute_overapping_documents_set(conv_id, curr_turn, f, qid_rel_dict):\n",
    "    \n",
    "    total_overlapping = 0\n",
    "    \n",
    "    utt_id = str(conv_id)+\"_\"+str(curr_turn)\n",
    "    docs_current_turn =  map_utt_docs[utt_id]\n",
    "\n",
    "    docs_so_far = set()\n",
    "    for turn_id in range(1, curr_turn):\n",
    "        if str(conv_id)+\"_\"+str(turn_id) in map_utt_docs:\n",
    "            my_list = map_utt_docs[str(conv_id)+\"_\"+str(turn_id)]\n",
    "            for el in my_list:                \n",
    "                docs_so_far.add(el)\n",
    "        else:\n",
    "            f.write(str(conv_id)+\"_\"+str(turn_id) + \" not found\\n\")\n",
    "    total_overlapping = len(intersection(docs_so_far, docs_current_turn))\n",
    "    # print(docs_so_far, docs_current_turn, total_overlapping)\n",
    "    normalized_overlapping = \"not in qrel\"\n",
    "    if utt_id in qid_rel_dict:\n",
    "        if qid_rel_dict[utt_id]>0:\n",
    "            normalized_overlapping = len(intersection(docs_so_far, docs_current_turn))/qid_rel_dict[utt_id]\n",
    "        else:\n",
    "            normalized_overlapping = \"0 relevants\"\n",
    "        \n",
    "    f.write(utt_id+\"\\t\"+str(total_overlapping)+\"\\t\"+str(qid_rel_dict[utt_id])+\"\\t\"+str(normalized_overlapping)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_overapping_with_first_utt_set(conv_id, curr_turn, f, qid_rel_dict, qid_retrieve_docids_dict):\n",
    "    \n",
    "    total_overlapping = 0\n",
    "    \n",
    "    utt_id = str(conv_id)+\"_\"+str(curr_turn)\n",
    "    docs_current_turn =  qid_retrieve_docids_dict[utt_id]\n",
    "    docs_first_turn =  qid_retrieve_docids_dict[str(conv_id)+\"_1\"]\n",
    "\n",
    "    \n",
    "    total_overlapping = len(intersection(docs_first_turn, docs_current_turn))\n",
    "    normalized_overlapping = \"not in qrel\"\n",
    "    \n",
    "    if utt_id in qid_rel_dict:\n",
    "        if qid_rel_dict[utt_id]>0:\n",
    "            normalized_overlapping = len(intersection(docs_first_turn, docs_current_turn))/qid_rel_dict[utt_id]\n",
    "        else:\n",
    "            normalized_overlapping = \"0 relevants\"\n",
    "        \n",
    "    f.write(utt_id+\"\\t\"+str(total_overlapping)+\"\\t\"+str(qid_rel_dict[utt_id])+\"\\t\"+str(normalized_overlapping)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main (with sets, no duplicates): to run after loading data\n",
    "\n",
    "path = \"../data/proof_of_concepts_preliminary_results/retrieved/top2000/\"\n",
    "with open(path+\"normalized-overalapping-sets-with-first-utt-docs.res_2019_manual.txt\", 'w') as f:\n",
    "    for el in qid_retrieve_docids_dict:\n",
    "        conv_id = int(el.split(\"_\")[0])\n",
    "        curr_turn = int(el.split(\"_\")[1])\n",
    "        compute_overapping_with_first_utt_set(conv_id, curr_turn, f, qid_rel_dict, qid_retrieve_docids_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conversational-cache",
   "language": "python",
   "name": "conversational-cache"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
